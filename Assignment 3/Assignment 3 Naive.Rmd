---
output:
  pdf_document: default
  html_document: default
---
Assignment 3 Manasa Pullabhatla 811284922

#Summary 
#In this problem we are trying to Our goal here is to predict whether an accident just reported will involve an injury or will not occur any injury. We have first created a reating a dummy variable called INJURY that takes the value “yes” if MAX_SEV_IR = 1 or 2, and otherwise “no" and then converted all the variables into factors.

#1 If MAX_SEV_IR is either 1 or 2, it suggests that the accident resulted in some form of injury. In contrast, when MAX_SEV_IR is 0, it indicates that no injuries were reported. So, when an accident has just been reported, and there is no additional information available, the prediction for "INJURY" should be "Yes." This is because MAX_SEV_IR being 1 or 2 implies the presence of an injury, while MAX_SEV_IR being 0 signifies the absence of injuries. To predict whether an accident will involve an injury, in the absence of further data, it's appropriate to assume there is an injury, leading to "INJURY" being marked as "Yes."
#2 1) Kindly look at the below output for Question 1
#2 2) With a cutoff of 0.5 there are 14 cases which didn't meet with an accident and 10 cases which met with an accident.
#2 3) The probability of a person getting injured when the weather condition is 1 and the traffic condition is 1 is determined to be 0. This information is obtained from Pivot 1, and the conditional table shows that when the weather condition is 1 and the traffic condition is 1, the probability is calculated as 1. However, when we compute the conditional probability, the result is 0 divided by 1, which equals 0.
#2 4)Out of the total 24 records we get to see that there are 10 injured cases and 14 non injured cases with the default threshold being set as 0.5. We also can see that the above count matches with the count achieved through manual calculation.
#3 1)We have first Created a data partition on the entire dataset with 60% being training and 40% validation and built the Naive Baye's model by considering the predicted variables, predicted the model on the validation set and binded the model's prediction with the labelled data.
#3 2)There are in total 16 cases wherein the model interpreted wrong i.e 16 cases are actually labelled as injured whereas the model interpreted as not injured i.e 16 False positive cases.


#Activating required libraries

```{r}
library(dplyr)
library(e1071)
library(caret)
```
#Loading Data set

```{r}
data.df <- read.csv("C:/Users/Sailaja/Documents/FML/accidentsfull.csv")
```


```{r}
colnames(data.df)
#Weather_R and Traf_con_R are deciding variables
```

#Creating a dummy variable called INJURY that takes the value “yes” if MAX_SEV_IR = 1 or 2, and otherwise “no.”

```{r}
data.df$INJURY <- data.df$MAX_SEV_IR
data.df$INJURY[data.df$MAX_SEV_IR==1] <- "Yes"
data.df$INJURY[data.df$MAX_SEV_IR==2] <- "Yes"
data.df$INJURY[data.df$MAX_SEV_IR==0] <- "No"

#To better interpret the values decoding yes and no to 1 and o

#data.df$INJURY <- ifelse(data.df$INJURY == "Yes",1,0)
```

#Converting all variables into factors
```{r}
data.df[sapply(data.df, is.integer)] <- lapply(data.df[sapply(data.df, is.integer)],as.factor)
data.df$INJURY <- as.factor(data.df$INJURY)
```

#1 Using the information in this dataset, if an accident has just been reported and no further information is available, what should the prediction be? (INJURY = Yes or No?) Why?

#If MAX_SEV_IR is either 1 or 2, it suggests that the accident resulted in some form of injury. In contrast, when MAX_SEV_IR is 0, it indicates that no injuries were reported. So, when an accident has just been reported, and there is no additional information available, the prediction for "INJURY" should be "Yes." This is because MAX_SEV_IR being 1 or 2 implies the presence of an injury, while MAX_SEV_IR being 0 signifies the absence of injuries. To predict whether an accident will involve an injury, in the absence of further data, it's appropriate to assume there is an injury, leading to "INJURY" being marked as "Yes."


#Subsetting the data

```{r}
data_to_use <- data.df[1:24,c("INJURY","WEATHER_R","TRAF_CON_R")]

```

#2 Select the first 24 records in the dataset and look only at the response (INJURY) and the two predictors WEATHER_R and TRAF_CON_R. Create a pivot table that examines INJURY as a function of the two predictors for these 24 records. Use all three variables in the pivot table as rows/columns.

```{r}
piv_1 <- ftable(data_to_use[,c(1:3)])
piv_1

piv_2 <- ftable(data_to_use[,-1])
piv_2
```
#2 1) Compute the exact Bayes conditional probabilities of an injury (INJURY = Yes) given the six possible combinations of the predictors.

```{r}
#p(INJURY="YES"/W,T)
y1 <- piv_1[3,1]/piv_2[1,1] #Weather =1, Traf Con =0)
y2 <- piv_1[4,1]/piv_2[2,1] #Weather =2, Traf Con =0)
y3 <- piv_1[3,2]/piv_2[1,2] #Weather =1, Traf Con =1)
y4 <- piv_1[4,2]/piv_2[2,2] #Weather =2, Traf Con =1)
y5 <- piv_1[3,3]/piv_2[1,3] #Weather =1, Traf Con =2)
y6 <- piv_1[4,3]/piv_2[2,3] #Weather =2, Traf Con =2)

#p(INJURY="NO"/W,T)
n1 <- piv_1[1,1]/piv_2[1,1] #Weather =1, Traf Con =0)
n2 <- piv_1[2,1]/piv_2[2,1] #Weather =2, Traf Con =0)
n3 <- piv_1[1,2]/piv_2[1,2] #Weather =1, Traf Con =1)
n4 <- piv_1[2,2]/piv_2[2,2] #Weather =2, Traf Con =1)
n5 <- piv_1[1,3]/piv_2[1,3] #Weather =1, Traf Con =2)
n6 <- piv_1[2,3]/piv_2[2,3] #Weather =2, Traf Con =2)

print(c(y1,y2,y3,y4,y5,y6))
print(c(n1,n2,n3,n4,n5,n6))

```
#2 b) Classify the 24 accidents using these probabilities and a cutoff of 0.5.

```{r}
prob.inj <- rep(0,24)

for (i in 1:24) {
  print(c(data_to_use$WEATHER_R[i],data_to_use$TRAF_CON_R[i]))
    if (data_to_use$WEATHER_R[i] == "1") {
      if (data_to_use$TRAF_CON_R[i]=="0"){
        prob.inj[i] = y1
      }
      else if (data_to_use$TRAF_CON_R[i]=="1") {
        prob.inj[i] = y3
      }
      else if (data_to_use$TRAF_CON_R[i]=="2") {
        prob.inj[i] = y5
      }
    }
    else {
      if (data_to_use$TRAF_CON_R[i]=="0"){
        prob.inj[i] = y2
      }
      else if (data_to_use$TRAF_CON_R[i]=="1") {
        prob.inj[i] = y4
      }
      else if (data_to_use$TRAF_CON_R[i]=="2") {
        prob.inj[i] = y6
      }
    }
  }
  
data_to_use$prob.inj <- prob.inj

data_to_use$pred.prob <- ifelse(data_to_use$prob.inj>0.5, "yes", "no")

table(data_to_use$pred.prob)
```
#With a cutoff of 0.5 there are 14 cases which didn't meet with an accident and 10 cases which met with an accident.

#2 c) Compute manually the naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1.
The probability of a person getting injured when the weather condition is 1 and the traffic condition is 1 is determined to be 0. This information is obtained from Pivot 1, and the conditional table shows that when the weather condition is 1 and the traffic condition is 1, the probability is calculated as 1. However, when we compute the conditional probability, the result is 0 divided by 1, which equals 0.

#2 d) Run a naive Bayes classifier on the 24 records and two predictors. Check the model output to obtain probabilities and classifications for all 24 records. Compare this to the exact Bayes classification. Are the resulting classifications equivalent? Is the ranking (= ordering) of observations equivalent?

```{r}
naive_model <- naiveBayes(INJURY ~ WEATHER_R + TRAF_CON_R, data = data_to_use)

pred_values <- predict(naive_model, data_to_use,type="raw")
pred_values

pred_values <- as.data.frame(pred_values)

pred_values$dec_var <- ifelse(pred_values$Yes>0.5,"Yes","No")
table(pred_values$dec_var)

```
#Out of the total 24 records we get to see that there are 10 injured cases and 14 non injured cases with the default threshold being set as 0.5. We also can see that the above count matches with the count achieved through manual calculation.

#3 Let us now return to the entire dataset. Partition the data into training (60%) and validation (40%). 
#3 a)Run a naive Bayes classifier on the complete training set with the relevant predictors (and INJURY as the response). Note that all predictors are categorical. Show the confusion matrix.

#Loading the dataset again to solve this specific question

```{r}
data_test <- read.csv("C:/Users/Sailaja/Documents/FML/accidentsfull.csv")

data_test$INJURY <- ifelse(data_test$MAX_SEV_IR >1, "Yes","No")

data_test$INJURY <- as.factor(data_test$INJURY)
```

```{r}
#Creating a data partition on the entire dataset with 60% being training and 40% validation

train_mod <- createDataPartition(data_test$INJURY, p=0.6, list=F)
train_1 <- data_test[train_mod,]
val_1 <- data_test[-train_mod,]

#Buiding the Naive Baye's model by considering the predicted variables 
mod <- naiveBayes(INJURY~.,data=data_test)

#Predicting the model on the validation set
pred_mod <- predict(mod, val_1)

#Binding the model's prediction with the labelled data
val_1 <- cbind(val_1, pred_mod)

```


#3 b)What is the overall error of the validation set?

```{r}
confusionMatrix(val_1$INJURY,val_1$pred_mod)
```
#There are in total 16 cases wherein the model interpreted wrong i.e 16 cases are actually labelled as injured whereas the model interpreted as not injured i.e 16 False positive cases.









